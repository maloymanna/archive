<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on Maloy Manna</title>
    <link>http://localhost:1313/tags/spark/</link>
    <description>Recent content in Spark on Maloy Manna</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2007 - 2019. All rights reserved.</copyright>
    <lastBuildDate>Wed, 18 Nov 2015 11:37:49 +0000</lastBuildDate>
    
	<atom:link href="http://localhost:1313/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Data processing with Spark in R &amp; Python</title>
      <link>http://localhost:1313/2015/11/18/data-processing-with-spark-in-r-python/</link>
      <pubDate>Wed, 18 Nov 2015 11:37:49 +0000</pubDate>
      
      <guid>http://localhost:1313/2015/11/18/data-processing-with-spark-in-r-python/</guid>
      <description>I recently gave a talk on data processing with Apache Spark using R and Python. tl;dr - the slides and presentation can be accessed below:
https://www.brighttalk.com/webcast/9059/172833
As noted in my previous post, Spark has become the defacto standard for big data applications and has been adopted quickly by the industry. See Cloudera&amp;rsquo;s One Platform initiative blog post by CEO Mike Olson for their commitment to Spark.
In data science R had seen rapid adoption, not only because it was open source and free compared to costly SAS, but also the huge number of statistical and graphical packages provided by R for data science.</description>
    </item>
    
    <item>
      <title>Set up a Hadoop Spark cluster in 10 minutes with Vagrant</title>
      <link>http://localhost:1313/2014/12/30/set-up-a-hadoop-spark-cluster-in-10-minutes-with-vagrant/</link>
      <pubDate>Tue, 30 Dec 2014 22:36:53 +0000</pubDate>
      
      <guid>http://localhost:1313/2014/12/30/set-up-a-hadoop-spark-cluster-in-10-minutes-with-vagrant/</guid>
      <description>With each of the big 3 Hadoop vendors - Cloudera, Hortonworks and MapR each providing their own Hadoop sandbox virtual machines (VMs), trying out Hadoop today has become extremely easy. For a developer, it is extremely useful to download a get started with one of these VMs and try out Hadoop to practice data science right away.
[caption id=&amp;ldquo;attachment_183&amp;rdquo; align=&amp;ldquo;alignnone&amp;rdquo; width=&amp;ldquo;326&amp;rdquo;] Set up a Hadoop-Spark cluster with Vagrant in 10 minutes[/caption]</description>
    </item>
    
    <item>
      <title>Basics of Big Data – Part 2 - Hadoop</title>
      <link>http://localhost:1313/2014/04/13/basics-of-big-data-part-2-hadoop/</link>
      <pubDate>Sun, 13 Apr 2014 18:12:16 +0000</pubDate>
      
      <guid>http://localhost:1313/2014/04/13/basics-of-big-data-part-2-hadoop/</guid>
      <description>As discussed in Part 1 of this series, _Hadoop _is the foremost among tools being currently used for deriving value out of Big Data. The process of gaining insights from data through Business Intelligence and analytics essentially remains the same. However, with the huge variety, volume and velocity (the 3Vs of Big Data), it’s become necessary to re-think of the data management infrastructure. Hadoop, originally designed to be used with the MapReduce algorithm to solve parallel processing constraints in distributed architectures (e.</description>
    </item>
    
  </channel>
</rss>